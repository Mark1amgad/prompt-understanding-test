# -*- coding: utf-8 -*-
import os
import re
import gradio as gr
from huggingface_hub import InferenceClient
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# -------- Settings --------
DEFAULT_MODEL = os.environ.get("MODEL_REPO", "HuggingFaceH4/zephyr-7b-beta")
HF_TOKEN = os.environ.get("HF_TOKEN", None)

_embedder = None
def get_embedder():
    global _embedder
    if _embedder is None:
        _embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
    return _embedder


def generate_response(prompt: str, model_repo: str = DEFAULT_MODEL, max_new_tokens: int = 256, temperature: float = 0.7):
    if not prompt or not prompt.strip():
        return "", 0.0, "Ø§Ù„Ù€Prompt ÙØ§Ø±Øº."

    if HF_TOKEN is None:
        return "", 0.0, "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¶Ø¨Ø· Ù…ÙØªØ§Ø­ HF_TOKEN ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù€Space."

    client = InferenceClient(model=model_repo, token=HF_TOKEN)
    try:
        chat_completion = client.chat.completions.create(
            model=model_repo,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_new_tokens,
            temperature=temperature,
        )
        text = chat_completion.choices[0].message["content"]
        return text, 1.0, "ØªÙ… Ø¨Ù†Ø¬Ø§Ø­."
    except Exception as e:
        return "", 0.0, f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}"


# ---------- Evaluation ----------
INSTRUCTION_HINTS = {
    "list_style": ["list", "Ù‚Ø§Ø¦Ù…Ø©", "Ø¹Ø¯Ù‘Ø¯", "Ø¹Ø¯", "bullet", "Ù†Ù‚Ø§Ø·", "â€¢", "â€“", "Ù¡.", "1."],
    "code_style": ["code", "ÙƒÙˆØ¯", "python", "java", "javascript", "js", "c++", "go", "rust"],
    "translate": ["ØªØ±Ø¬Ù…", "translate", "translation", "to english", "to arabic", "Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"],
    "summarize": ["Ø§Ø®ØªØµØ±", "Ù„Ø®Ù‘Øµ", "summarize", "summary", "Ù…Ù„Ø®Øµ"],
}


def detect_expected_format(prompt: str):
    p = prompt.lower()
    found = set()
    for key, kws in INSTRUCTION_HINTS.items():
        for kw in kws:
            if kw in p:
                found.add(key)
                break
    return found


def format_score(prompt: str, response: str):
    expected = detect_expected_format(prompt)

    if not expected:
        return 0.0, ["Ø§Ù„Ù€Prompt Ù„Ø§ ÙŠØ·Ù„Ø¨ ØªÙ†Ø³ÙŠÙ‚Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ù‹Ø§ØŒ Ù„Ø°Ù„Ùƒ Ù„Ù… ÙŠØªÙ… Ø§Ø­ØªØ³Ø§Ø¨ Ø¯Ø±Ø¬Ø© ØªÙ†Ø³ÙŠÙ‚."]

    reasons = []
    score = 0.0

    if "list_style" in expected:
        has_list = bool(re.search(r"(?:^|\n)\s*(?:[-*â€¢â€“]|\d+\.)\s+\S+", response))
        score += 1.0 if has_list else 0.0
        reasons.append("Ù‚Ø§Ø¦Ù…Ø©/Ù†Ù‚Ø§Ø·: " + ("âœ…" if has_list else "âŒ"))

    if "code_style" in expected:
        has_code = bool(re.search(r"```[\s\S]*?```", response))
        score += 1.0 if has_code else 0.0
        reasons.append("ØªÙ†Ø³ÙŠÙ‚ ÙƒÙˆØ¯: " + ("âœ…" if has_code else "âŒ"))

    if "translate" in expected:
        arabic = bool(re.search(r"[\u0600-\u06FF]", response))
        latin = bool(re.search(r"[A-Za-z]", response))
        has_translation = arabic and latin
        score += 0.8 if has_translation else 0.0
        reasons.append("Ø¥Ø´Ø§Ø±Ø§Øª ØªØ±Ø¬Ù…Ø©: " + ("âœ…" if has_translation else "âŒ"))

    if "summarize" in expected:
        shorter = len(response.split()) < max(40, len(prompt.split()))
        score += 0.8 if shorter else 0.0
        reasons.append("ØªÙ„Ø®ÙŠØµ: " + ("âœ…" if shorter else "âŒ"))

    max_possible = 0.0
    max_possible += 1.0 if "list_style" in expected else 0.0
    max_possible += 1.0 if "code_style" in expected else 0.0
    max_possible += 0.8 if "translate" in expected else 0.0
    max_possible += 0.8 if "summarize" in expected else 0.0
    max_possible = max(max_possible, 1e-6)

    return float(score / max_possible), reasons


def similarity_score(prompt: str, response: str):
    emb = get_embedder()
    vecs = emb.encode([prompt, response])
    sim = cosine_similarity([vecs[0]], [vecs[1]])[0][0]
    return float(sim)


def length_score(response: str):
    w = len(response.split())
    return float(np.clip((w - 10) / (60 - 10), 0, 1))


def overall_evaluate(prompt: str, response: str):
    try:
        sim = similarity_score(prompt, response)
        sim01 = (sim + 1) / 2.0
    except Exception:
        sim01 = 0.0

    fmt, fmt_reasons = format_score(prompt, response)
    lng = length_score(response)

    # â›” Ù„Ø§ Ù†Ø­Ø³Ø¨ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù„Ùˆ ØºÙŠØ± Ù…Ø·Ù„ÙˆØ¨
    if fmt_reasons and "Ù„Ø§ ÙŠØ·Ù„Ø¨ ØªÙ†Ø³ÙŠÙ‚Ù‹Ø§" in fmt_reasons[0]:
        score01 = 0.6 * sim01 + 0.4 * lng
    else:
        score01 = 0.6 * sim01 + 0.2 * fmt + 0.2 * lng

    score100 = round(score01 * 100, 1)

    if score100 >= 70:
        verdict = "âœ”âœ” Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙÙ‡ÙÙ… Ø§Ù„Ù€Prompt Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯"
    elif score100 >= 50:
        verdict = "âš ï¸ Ø§Ù„ÙÙ‡Ù… Ù…ØªÙˆØ³Ø· â€“ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†"
    else:
        verdict = "âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠÙÙ‡Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§ÙÙ"

    details = {
        "ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© (0-100)": round(sim01 * 100, 1),
        "Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (0-100)": round(fmt * 100, 1),
        "Ø«Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (0-100)": round(lng * 100, 1),
        "Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„ÙƒÙ„ÙŠØ© (0-100)": score100,
        "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„ØªÙ†Ø³ÙŠÙ‚": " | ".join(fmt_reasons),
    }

    return score100, verdict, details


def run_test(prompt, model_repo, max_new_tokens, temperature):
    response, ok, status = generate_response(prompt, model_repo, max_new_tokens, temperature)
    if not response:
        return "", status, {}, "", 0

    score, verdict, details = overall_evaluate(prompt, response)
    details_txt = "\n".join([f"- {k}: {v}" for k, v in details.items()])

    return response, verdict, details, details_txt, details["Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„ÙƒÙ„ÙŠØ© (0-100)"]


# ------------- UI -------------
with gr.Blocks(theme="soft", title="Ø§Ø®ØªØ¨Ø§Ø± ÙÙ‡Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ù†ØµÙˆØµ") as demo:
    gr.Markdown("# ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ÙÙ‡Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ù†ØµÙˆØµ (Prompt Understanding Test)")
    gr.Markdown("> âœ¨ Ø§ÙƒØªØ¨ Ø£ÙŠ Prompt ÙˆØ´Ø§Ù‡Ø¯ Ø±Ø¯Ù‘ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙÙ‡Ù… ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§")

    model_repo = gr.Dropdown(
        choices=[
            "HuggingFaceH4/zephyr-7b-beta",
            "google/gemma-2-2b-it",
        ],
        value=DEFAULT_MODEL,
        label="HF Model Repo",
    )

    prompt = gr.Textbox(lines=5, label="âœï¸ Ø§ÙƒØªØ¨ Ø§Ù„Ù€Prompt Ù‡Ù†Ø§")

    with gr.Row():
        ex1 = gr.Button("âœ¨ Ù…Ø«Ø§Ù„: Ù‚Ø§Ø¦Ù…Ø©")
        ex2 = gr.Button("ğŸ§‘â€ğŸ’» Ù…Ø«Ø§Ù„: ÙƒÙˆØ¯")
        ex3 = gr.Button("ğŸŒ Ù…Ø«Ø§Ù„: ØªØ±Ø¬Ù…Ø©")

    max_new_tokens = gr.Slider(32, 512, value=256, label="Max New Tokens")
    temperature = gr.Slider(0.0, 1.5, value=0.7, label="Temperature")

    btn = gr.Button("ğŸš€ Ø§Ø®ØªØ¨Ø± Ø§Ù„Ø¢Ù†")

    with gr.Tab("ğŸ“ Ø±Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"):
        response = gr.Textbox(lines=10)

    with gr.Tab("âœ… Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"):
        verdict = gr.Label()
        score_bar = gr.Slider(0, 100, interactive=False)

    with gr.Tab("ğŸ“Š Ø§Ù„ØªÙØ§ØµÙŠÙ„"):
        details_dict = gr.JSON()
        details_txt = gr.Textbox(lines=6)

    btn.click(
        fn=run_test,
        inputs=[prompt, model_repo, max_new_tokens, temperature],
        outputs=[response, verdict, details_dict, details_txt, score_bar],
    )

    ex1.click(lambda: "Ø§ÙƒØªØ¨ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† 5 Ø£ÙÙƒØ§Ø± Ù„Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.", outputs=prompt)
    ex2.click(lambda: "Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Python Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¶Ø±ÙˆØ¨.", outputs=prompt)
    ex3.click(lambda: "Translate this sentence to Arabic: Artificial intelligence changes the world.", outputs=prompt)

if __name__ == "__main__":
    demo.launch()
